# Comandos Optimizados para Servidor - 10M Samples

## üöÄ Comando Principal para 10M samples

```bash
python hrm_training_micro_10m_standalone_hf.py \
  --train_samples 10000000 \
  --val_samples 50000 \
  --epochs 1 \
  --batch_size 16 \
  --learning_rate 0.000025 \
  --num_workers 8 \
  --prefetch_factor 4 \
  --val_check_interval 5000 \
  --save_steps 10000 \
  --max_grad_norm 0.5 \
  --output_dir ./hrm-micro-10m-server \
  --device auto
```

## ‚ö° Configuraciones por tipo de servidor

### **GPU Server (CUDA)**
```bash
python hrm_training_micro_10m_standalone_hf.py \
  --train_samples 10000000 \
  --val_samples 50000 \
  --epochs 1 \
  --batch_size 32 \
  --learning_rate 0.00004 \
  --num_workers 12 \
  --prefetch_factor 8 \
  --val_check_interval 2500 \
  --save_steps 5000 \
  --max_grad_norm 0.5 \
  --device cuda \
  --output_dir ./hrm-micro-10m-gpu
```

### **CPU Server (High cores)**  
```bash
python hrm_training_micro_10m_standalone_hf.py \
  --train_samples 10000000 \
  --val_samples 50000 \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 0.000015 \
  --cpu_intensive \
  --batch_size_multiplier 2 \
  --num_workers 16 \
  --prefetch_factor 2 \
  --val_check_interval 10000 \
  --save_steps 25000 \
  --max_grad_norm 0.5 \
  --device cpu \
  --output_dir ./hrm-micro-10m-cpu
```

### **Memory Optimized**
```bash
python hrm_training_micro_10m_standalone_hf.py \
  --train_samples 10000000 \
  --val_samples 25000 \
  --epochs 1 \
  --batch_size 4 \
  --learning_rate 0.000015 \
  --num_workers 4 \
  --prefetch_factor 2 \
  --val_check_interval 5000 \
  --save_steps 15000 \
  --max_grad_norm 0.5 \
  --no_streaming \
  --output_dir ./hrm-micro-10m-mem
```

## üéØ Par√°metros clave explicados

### **Early Stopping (autom√°tico para 10M+)**
- **Patience: 5** - Detiene despu√©s de 5 evaluaciones sin mejora
- **Min Delta: 0.001** - Mejora m√≠nima requerida
- **Autom√°tico** - Se activa solo para datasets >= 1M samples

### **Learning Rates recomendados (ULTRA-CONSERVADORES)**
- **GPU potente**: 0.000025-0.00004 (20x m√°s bajo que el original)
- **CPU/GPU d√©bil**: 0.000015-0.000025 (33x m√°s bajo que el original)
- **Memoria limitada**: 0.000015

**üö® CR√çTICO**: Incluso los LR "corregidos" anteriores segu√≠an causando convergencia lineal demasiado r√°pida. Estos valores ultra-bajos son necesarios para evitar memorizaci√≥n.

### **Batch Sizes por hardware**
- **GPU 24GB+**: batch_size 32-64
- **GPU 8-16GB**: batch_size 16-24  
- **CPU potente**: batch_size 8-16
- **Memoria limitada**: batch_size 4-8

### **Workers y Prefetch**
- **GPU**: num_workers=12, prefetch_factor=8
- **CPU**: num_workers=16, prefetch_factor=2
- **Limitado**: num_workers=4, prefetch_factor=2

## üìä Monitoreo recomendado

### **M√©tricas objetivo (CON LEARNING RATE ULTRA-BAJO)**
- **Val Loss objetivo**: 2.8 - 4.5 (realista con LR ultra-conservador)
- **Perplexity objetivo**: 16.0 - 90.0 (sin memorizaci√≥n, evitar < 12.0)
- **Steps estimados**: ~1.25M steps para 10M samples
- **Convergencia**: MUY lenta con mesetas y fluctuaciones naturales

### **Se√±ales de √©xito**
```
‚úÖ Val Loss final entre 3.0-4.0 (NO m√°s bajo)
‚úÖ Convergencia con mesetas y fluctuaciones
‚úÖ Perplexity 18.0-40.0 (sin memorizaci√≥n)
‚úÖ Generaci√≥n de texto coherente sin repetici√≥n
‚úÖ Progreso lento pero estable (sin ca√≠das lineales)
```

### **Se√±ales de problema**
```
‚ùå Val Loss < 2.0 (overfitting severo)
‚ùå Perplexity < 12.0 (memorizaci√≥n) 
‚ùå Ca√≠da lineal constante sin fluctuaciones
‚ùå Convergencia demasiado r√°pida (como tu caso actual)
‚ùå Early stopping antes de 200k steps
‚ùå Generaci√≥n repetitiva o incoherente
```

## üö® Comandos de emergencia

### **Reanudar desde checkpoint**
```bash
python hrm_training_micro_10m_standalone_hf.py \
  --resume_from_checkpoint ./hrm-micro-10m-server/checkpoint-50000 \
  --train_samples 10000000 \
  --val_samples 50000
```

### **Reducir recursos si falla**
```bash
# Reducir batch size y workers si hay OOM
python hrm_training_micro_10m_standalone_hf.py \
  --train_samples 10000000 \
  --val_samples 50000 \
  --batch_size 2 \
  --num_workers 2 \
  --prefetch_factor 1
```

## üéõÔ∏è Configuraciones avanzadas

### **Dataset streaming (recomendado)**
- Por defecto est√° activado
- Usa `--no_streaming` solo si tienes 500GB+ RAM disponible

### **Tokenizer optimizations**
- Se ajustan autom√°ticamente seg√∫n CPU cores
- Para servidores 32+ cores, el paralelismo ser√° m√°ximo

### **Gradient accumulation** 
- Se calcula autom√°ticamente si batch_size * batch_size_multiplier < 16
- Para simular batch sizes m√°s grandes en hardware limitado

## üìà Timeline esperado

**10M samples, 1 √©poca:**
- **GPU V100/A100**: 8-12 horas
- **GPU RTX 4090**: 12-18 horas  
- **CPU 32-cores**: 2-4 d√≠as
- **CPU 16-cores**: 4-7 d√≠as

**Checkpoints recomendados cada:**
- **GPU**: 5,000-10,000 steps
- **CPU**: 15,000-25,000 steps